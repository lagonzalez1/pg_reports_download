# ğŸ“Š RabbitMQ Consumer: PostgreSQL Insights â†’ CSV â†’ S3

This project implements a **RabbitMQ consumer service** that:

1. **Consumes jobs** from a RabbitMQ queue.  
2. **Pulls data** from a PostgreSQL database based on the job payload.  
3. **Generates insights** and transforms the results into a structured **CSV file**.  
4. **Uploads the CSV file to Amazon S3**.  
5. Provides a **download link (presigned URL)** so clients can securely retrieve the file.

---

## âš™ï¸ Architecture

- **Producer** publishes a job (JSON payload) â†’ `generate_csv` queue.  
- **Consumer** receives job, runs a query against **PostgreSQL**, generates insights.  
- Results are saved as `.csv` and uploaded to **S3**.  
- A **presigned S3 URL** is returned to the client for download.  

---

## ğŸ“‚ Project Structure

.
â”œâ”€â”€ Config/
â”‚   â”œâ”€â”€ Client.py
â”‚   â”œâ”€â”€ RabbitMQ.py
â”‚   â””â”€â”€ PostgresClient.py
â”œâ”€â”€ Parser/
â”‚   â”œâ”€â”€ StudentParser.py
â”‚   â”œâ”€â”€ TutorParser.py
â”‚   â””â”€â”€ test
â”œâ”€â”€ S3/
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ main.py  
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ Makefile
â”œâ”€â”€ Requirements.txt 
â””â”€â”€ README.md


---

## ğŸ”§ Setup

### 1. Requirements

- Python 3.9+
- RabbitMQ server
- PostgreSQL
- AWS S3 bucket

Install dependencies:

```bash
pip install -r requirements.txt